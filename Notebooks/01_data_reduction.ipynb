{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made by Yoonsoo P. Bach\n",
    "\n",
    "# KMTNet Data Reduction\n",
    "Because of the data protection issue, I cannot provide the data here (even if possible, the original data are as large as ~ 100 GB). What I was provided are the 2K by 2K data cropped around the target (4179) Toutatis, after\n",
    "1. Image acquisition\n",
    "2. Pre-processing done at KMTNet Data Center\n",
    "2. WCS updated and cropped around the target (4179) Toutatis using ``MODP`` (Moving Object Detection Pipeline) by one of our co-authors (Y. JeongAhn).\n",
    "\n",
    "If you are interested in the data reduction, please contact me via dbstn95@gmail.com, and I will ask KASI side for a permission for the data distribution. \n",
    "\n",
    "Thus, I will show \n",
    "1. The codes I used for the data reduction and some simple explanations\n",
    "2. A snapshot of the package ``yspy``. ``yspy`` is now splitted into many sub-packages, and are planned to be distributed in the near future as citable manner via Zenodo (Y. P. Bach, 2019, in prep). We put a snapshot in this repo to guarantee a certain degree of reproducibility.\n",
    "3. Few of the images of the reduced images\n",
    "\n",
    "\n",
    "* **NOTE**: As mentioned above, **I will not show or distribute any raw data in this notebook**.\n",
    "* **NOTE**: The codes shown here are not coded for general purpose, but to be used as *quick-and-dirty* solution for our data reduction, so please be cautious when you want to use any part of this notebook for your scientific purpose.\n",
    "\n",
    "## Testing Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was generated at 2019-20-01 15:46:01 (KST = GMT+0900) \n",
      "0 Python     3.6.7 64bit [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "1 IPython    6.5.0\n",
      "2 OS         Darwin 18.2.0 x86_64 i386 64bit\n",
      "3 scipy      1.1.0\n",
      "4 numpy      1.15.4\n",
      "5 matplotlib 3.0.1\n",
      "6 pandas     0.23.4\n",
      "7 astropy    3.1\n",
      "8 photutils  0.6\n",
      "9 ccdproc    1.3.0.post1\n",
      "10 callhorizons 1.1.1\n",
      "11 version_information 1.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ysbach/anaconda3/lib/python3.6/site-packages/CALLHORIZONS-1.1.1-py3.6.egg/callhorizons/callhorizons.py:43: DeprecationWarning: CALLHORIZONS is not maintained anymore; please use astroquery.jplhorizons instead (https://github.com/astropy/astroquery)\n"
     ]
    }
   ],
   "source": [
    "%load_ext version_information\n",
    "import time\n",
    "now = time.strftime(\"%Y-%d-%m %H:%M:%S (%Z = GMT%z)\")\n",
    "print(f\"This notebook was generated at {now} \")\n",
    "\n",
    "vv = %version_information scipy, numpy, matplotlib, pandas, astropy, photutils, ccdproc, callhorizons, version_information\n",
    "for i, pkg in enumerate(vv.packages):\n",
    "    print(f\"{i} {pkg[0]:10s} {pkg[1]:s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package ``callhorizons`` made by M. Mommert is available at [this GitHub repo](https://github.com/mommermi/callhorizons). It is superseded by ``astroquery``'s ``jplhorizons`` module as the above warning indicates.\n",
    "\n",
    "## Reduction Codes\n",
    "\n",
    "First, I imported as below:\n",
    "\n",
    "-----\n",
    "```python\n",
    "import os\n",
    "from pathlib import Path\n",
    "from warnings import warn as W\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from yspy.util import fits_util as fu\n",
    "from yspy.util import preproc\n",
    "from yspy.util.graphics import zimshow\n",
    "from yspy.instruments import KMTNet\n",
    "from yspy.query import astroquery_util, astrometry_client, horizons, panstarrs\n",
    "from yspy.query import utils as qu\n",
    "from yspy.postproc import photometry, source_find\n",
    "from yspy.simulation import phase\n",
    "\n",
    "from astropy.nddata import CCDData, Cutout2D\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.wcs import WCS\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy.table import Table, vstack, hstack\n",
    "from astropy.time import Time\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "\n",
    "import ccdproc\n",
    "\n",
    "from photutils.detection import DAOStarFinder\n",
    "from photutils import CircularAnnulus as Can\n",
    "from photutils import CircularAperture as Cap\n",
    "from photutils.psf.groupstars import DAOGroup\n",
    "```\n",
    "-----\n",
    "\n",
    "Then set the paths for your computer system:\n",
    "\n",
    "-----\n",
    "```python\n",
    "# Macbook\n",
    "deepsouthpath = Path('/', 'Users', 'ysbach', 'Dropbox', 'workspace', \n",
    "                     'cowork', 'KMTNet_Toutatis', 'deepsouth')\n",
    "# LINUX\n",
    "if not deepsouthpath.exists():\n",
    "    deepsouthpath = Path('/', 'home', 'ysbach', 'Dropbox', 'workspace', 'cowork', \n",
    "                         'KMTNet_Toutatis', 'deepsouth')\n",
    "    \n",
    "if Path.cwd() != deepsouthpath:\n",
    "    os.chdir(deepsouthpath)\n",
    "    \n",
    "    \n",
    "crrej_dir = Path('..', \"crrej_1k\")\n",
    "reduc_dir = Path('..', \"reduc\")\n",
    "\n",
    "# We visually selected some bad images, and these images will be rejected in the codes below.\n",
    "REJECT = ['20180407CTIO_p4179_016781.fits', '20180409SSO_p4179_051334.fits', \n",
    "          '20180413CTIO_p4179_018271.fits', '20180407CTIO_p4179_016782.fits', \n",
    "          '20180411SSO_p4179_051984.fits', '20180413CTIO_p4179_018272.fits',\n",
    "          '20180407CTIO_p4179_016783.fits', '20180411SSO_p4179_051992.fits', \n",
    "          '20180413CTIO_p4179_018273.fits', '20180409CTIO_p4179_017408.fits', \n",
    "          '20180411SSO_p4179_051993.fits', '20180413CTIO_p4179_018274.fits', \n",
    "          '20180409SSO_p4179_051333.fits', '20180413CTIO_p4179_018270.fits', \n",
    "          '20180413CTIO_p4179_018275.fits']\n",
    "    \n",
    "cutsize_crrej = 1000  # For CR rejection\n",
    "cutsize_targ = 200    # For the target-extracted images\n",
    "rejected = []\n",
    "minsep_star = 10\n",
    "target = '4179'\n",
    "\n",
    "fu.mkdir(crrej_dir)\n",
    "fu.mkdir(reduc_dir)\n",
    "\n",
    "summary = fu.load_if_exists(\"summary.csv\", loader=Table.read)\n",
    "\n",
    "if not Path(\"summary.csv\").exists():\n",
    "    allfits = list(Path('.').glob('**/*.fits'))\n",
    "    tabs = []\n",
    "    summary0 = fu.make_summary(allfits, fname_option=\"relative\",\n",
    "                              keywords=KMTNet.USEFUL_HEADER_KEYS)\n",
    "    summary0[\"date\"] = summary0[\"file\"].copy()\n",
    "\n",
    "    for i, dt in enumerate(summary0[\"date\"]):\n",
    "        summary0[\"date\"][i] = dt.split('/')[0]\n",
    "    \n",
    "    for obs in [\"CTIO\", \"SSO\", \"SAAO\"]:\n",
    "        obscode = KMTNet.OBSERVATORY_CODE[obs]\n",
    "        tab = summary0[summary0[\"OBSERVAT\"] == obs]\n",
    "        epochs = Time(tab[\"DATE-OBS\"]).jd\n",
    "        q = horizons.DiscreteEpochQuery(target, obscode, epochs)\n",
    "        q.query()\n",
    "        qt = q.query_table['RA', 'DEC', 'RA_rate', 'DEC_rate', \n",
    "                           \"RA_3sigma\", \"DEC_3sigma\", 'V', 'r', 'r_rate',\n",
    "                           'delta', 'delta_rate', 'lighttime', 'alpha',\n",
    "                           'ObsEclLon', 'ObsEclLat']\n",
    "        qt[\"RA\"].name=\"RA_deg\"\n",
    "        qt[\"DEC\"].name=\"DEC_deg\"\n",
    "        \n",
    "        tabs.append(hstack([tab, qt]))\n",
    "        \n",
    "    summary = vstack(tabs)\n",
    "    summary.write(\"summary.csv\")\n",
    "\n",
    "grouped = summary.group_by(\"date\")\n",
    "```\n",
    "-----\n",
    "\n",
    "Then for all the date-grouped images, do cosmic-ray rejection and sidereal stacking (called ``star``) and target-centered stacking (called ``targ``).\n",
    "\n",
    "-----\n",
    "```python\n",
    "for group in grouped.groups:\n",
    "    ccds_star = []\n",
    "    ccds_targ = []\n",
    "    asts = []\n",
    "    uts = []\n",
    "    wcs_ref = None\n",
    "    starpath = reduc_dir / (group[\"date\"][0] + '_star.fits')\n",
    "    targpath = reduc_dir / (group[\"date\"][0] + '_targ.fits')\n",
    "    \n",
    "#    if not starpath.exists() or not targpath.exists():\n",
    "    for i, row in enumerate(group):\n",
    "        fpath = Path(row[\"file\"])\n",
    "        astpath = fpath.parent / (fpath.name[:-4] + 'ast')\n",
    "        pngpath = crrej_dir / (fpath.parts[-2] + '_' + fpath.name[:-4] + 'png')\n",
    "        crpath = crrej_dir / (fpath.parts[-2] + '_' + fpath.name)\n",
    "        if crpath.name in REJECT:\n",
    "            continue\n",
    "        print(fpath)\n",
    "        \n",
    "        ast = fu.read_without_newline(astpath)\n",
    "        if len(ast) != 1:\n",
    "            W(\"Position file has {len(ast):d} contents! Only the first one will be used.\")\n",
    "        \n",
    "        hdu_0 = fits.open(fpath)[0]\n",
    "        hdr_0 = hdu_0.header\n",
    "        uts.append((Time(hdr_0[\"DATE-OBS\"], format='isot') \n",
    "                    + hdr_0[\"EXPTIME\"] * u.s / 2).jd)\n",
    "        wcs_0 = WCS(hdr_0)\n",
    "        ccd_0 = CCDData(data=hdu_0.data, header=hdu_0.header, wcs=wcs_0, \n",
    "                        unit='adu')\n",
    "        coord = SkyCoord(row[\"RA_deg\"], row[\"DEC_deg\"], unit=u.deg)\n",
    "        ast_0 = coord.to_pixel(wcs = wcs_0, origin = 0)  # xy\n",
    "        # origin = 0 means 0-indexing\n",
    "        \n",
    "        # Check whether there's nearby sidereal object.\n",
    "        plt.close('all')\n",
    "        ast_0_com = photometry.find_centroid_com(ccd_0, ast_0, \n",
    "                                                 cbox_size=minsep_star / 2,\n",
    "                                                 csigma=0.1)\n",
    "#        print(\"dx, dy = \", np.array(ast_0) - np.array(ast_0_com))\n",
    "#        nostar = photometry.check_nostar_convolve(ccd_0,\n",
    "#                                                  kernel=Gaussian2DKernel(2),\n",
    "#                                                  minsep_I0=minsep_star,\n",
    "#                                                  position=ast_0_com,\n",
    "#                                                  size=cutsize_targ,\n",
    "#                                                  mask_size=minsep_star,\n",
    "#                                                  box_size=5,\n",
    "#                                                  ksigma=0.8,\n",
    "#                                                  border_width=5,\n",
    "#                                                  show_plot=True)\n",
    "#        plt.tight_layout()\n",
    "#        plt.savefig(pngpath, dpi=200)\n",
    "#        plt.close('all')\n",
    "        \n",
    "#        if nostar:\n",
    "        # Crop first since CR rejection & reprojection takes long time...\n",
    "        ccd_1 = preproc.cutout2trim(ccd_0, position=ast_0_com, \n",
    "                                    size=cutsize_crrej, full=False)\n",
    "\n",
    "        if wcs_ref is None:\n",
    "            wcs_ref = ccd_1.wcs\n",
    "\n",
    "        # CR rejection\n",
    "        ccd_1_cr = fu.load_if_exists(crpath, loader=fits.open, verbose=False)\n",
    "        if ccd_1_cr is None:\n",
    "            continue\n",
    "#            ccd_1_cr = preproc.crrej_LA(ccd_1, output=crpath)\n",
    "        else:\n",
    "            ccd_1_cr = CCDData(data=ccd_1_cr[0].data,\n",
    "                               header=ccd_1_cr[0].header,\n",
    "                               wcs=WCS(ccd_1_cr[0].header),\n",
    "                               unit='adu')\n",
    "        \n",
    "        # WCS projection\n",
    "        proj = ccdproc.wcs_project(ccd_1_cr, target_wcs=wcs_ref, \n",
    "                                   target_shape=(cutsize_crrej, cutsize_crrej))\n",
    "        \n",
    "        # Crop around Toutatis for non-sidereal stacking\\\n",
    "        ast_ref = coord.to_pixel(wcs = wcs_ref, origin = 0)\n",
    "        ccd_2 = preproc.cutout2trim(proj, position=ast_ref, \n",
    "                                    size=cutsize_targ, full=False)\n",
    "    \n",
    "        ccds_star.append(proj)\n",
    "        ccds_targ.append(ccd_2)\n",
    "        \n",
    "        asts.append(ast_0_com)\n",
    "    \n",
    "#        else:\n",
    "#            rejected.append(fpath)\n",
    "    # Mean time is used for future query\n",
    "    time_obs = Time(np.mean(uts), format='jd')\n",
    "#    plt.close('all')\n",
    "    comb_star = ccdproc.combine(ccds_star, method='sum')\n",
    "    comb_star.header[\"NCOMBINE\"] = len(ccds_star)\n",
    "    comb_star.header[\"MEANTIME\"] = str(time_obs.isot)\n",
    "    comb_star = fu.CCDData_astype(comb_star, 'float32')\n",
    "    comb_star.write(starpath, overwrite=True)\n",
    "#    fig, ax = plt.subplots(1,1)\n",
    "#    c = zimshow(ax, comb_star.data)\n",
    "#    plt.colorbar(c)\n",
    "#    plt.close('all')\n",
    "    \n",
    "    comb_targ = ccdproc.combine(ccds_targ, method='sum')\n",
    "    comb_targ.header[\"NCOMBINE\"] = len(ccds_targ)\n",
    "    comb_targ.header[\"MEANTIME\"] = str(time_obs.isot)\n",
    "    comb_targ = fu.CCDData_astype(comb_targ, 'float32')\n",
    "    comb_targ.write(targpath, overwrite=True)\n",
    "#    fig, ax = plt.subplots(1,1)\n",
    "#    c = zimshow(ax, comb_targ.data)\n",
    "#    plt.colorbar(c)\n",
    "#    plt.close('all')\n",
    "```\n",
    "-----\n",
    "\n",
    "Next, do photometry. The detailed process is described in the original publication, so I will not explain much detail.\n",
    "\n",
    "For the bad-pixels for each image (the ``reduc_dir / \"badpix.csv\"`` in the code below), you may use the following csv contents:\n",
    "\n",
    "```\n",
    "file,xmin,xmax,ymin,ymax\n",
    "20180407CTIO_star.fits,685,835,1,210\n",
    "20180407SAAO_star.fits,806,826,1,1000\n",
    "20180407SSO_star.fits,401,416,1,1000\n",
    "20180407SSO_star.fits,612,626,1,1000\n",
    "20180409SSO_star.fits,117,130,1,1000\n",
    "20180411SSO_star.fits,602,715,274,372\n",
    "20180411SSO_star.fits,655,662,274,1000\n",
    "20180413CTIO_star.fits,86,177,804,895\n",
    "20180413CTIO_star.fits,126,133,1,803\n",
    "20180413CTIO_star.fits,854,941,917,1000\n",
    "20180413CTIO_star.fits,894,902,1,916\n",
    "20180413SAAO_star.fits,792,801,1,1000\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "-----\n",
    "```python\n",
    "reduc = list(reduc_dir.glob(\"*.fits\"))\n",
    "fwhm = 4\n",
    "r_ap = 1.5 * fwhm\n",
    "r_in = 4 * fwhm\n",
    "r_out = 6 * fwhm\n",
    "crit_sep = r_out + r_ap\n",
    "catalog_Vmin = 15\n",
    "catalog_Vmax = 20\n",
    "maskbox_size = 100\n",
    "bezel_size = 100\n",
    "\n",
    "badpix = Table.read(reduc_dir / \"badpix.csv\", format='ascii.csv')\n",
    "\n",
    "targ_phots = []\n",
    "star_phots = []\n",
    "\n",
    "for fpath in reduc:\n",
    "    print(fpath.name)\n",
    "    ccd = fu.load_ccd(fpath)\n",
    "    t_exp = ccd.header[\"EXPTIME\"]\n",
    "    t_mean = Time(ccd.header[\"MEANTIME\"], format='isot').jd\n",
    "    gain_epadu = float(ccd.header[\"GAIN\"])\n",
    "    rdnoise_e = float(ccd.header[\"RDNOISE\"]) * np.sqrt(ccd.header[\"NCOMBINE\"])\n",
    "    avg, med, std = sigma_clipped_stats(ccd.data, sigma=3, iters=5)\n",
    "\n",
    "    if fpath.name.endswith(\"_targ.fits\"):\n",
    "        # Query for target at mean time\n",
    "        obscode = KMTNet.OBSERVATORY_CODE[fpath.name.split('_')[0][8:]]\n",
    "        q = horizons.DiscreteEpochQuery(target, obscode, [t_mean])\n",
    "        q.query()\n",
    "        qt = q.query_table['datetime_jd', 'RA', 'DEC', 'RA_rate', 'DEC_rate', \n",
    "                           \"RA_3sigma\", \"DEC_3sigma\", 'V', 'r', 'r_rate',\n",
    "                           'delta', 'delta_rate', 'lighttime', 'alpha',\n",
    "                           'ObsEclLon', 'ObsEclLat']\n",
    "        qt[\"V\"].name = \"V_JPL\"\n",
    "        qt[\"RA\"].name = \"RA_deg\"\n",
    "        qt[\"DEC\"].name = \"DEC_deg\"\n",
    "        \n",
    "        errmap = fu.make_errmap(ccd, gain_epadu=gain_epadu, \n",
    "                                rdnoise_electron=rdnoise_e)\n",
    "        pos = (cutsize_targ/2 + 0.5, cutsize_targ/2 + 0.5)\n",
    "        pos = photometry.find_centroid_com(ccd, pos, csigma=1)\n",
    "        ap = Cap(positions=pos, r=r_ap)\n",
    "        an = Can(positions=pos, r_in=r_in, r_out=r_out)    \n",
    "        mask = (ccd.data > med + 3 * std)\n",
    "        revive_targ = np.nonzero(ap.to_mask()[0].to_image(ccd.data.shape))\n",
    "        mask[revive_targ] = False\n",
    "        np.save(fpath.parent / (fpath.name[:-4] + 'mask'), mask)\n",
    "       \n",
    "        phot = photometry.apphot_annulus(ccd, aperture=ap, annulus=an, \n",
    "                                         mask=mask, t_exposure=t_exp, \n",
    "                                         error=errmap)\n",
    "        phot[\"file\"]=fpath.name\n",
    "        phot = hstack([phot, qt])\n",
    "        targ_phots.append(phot)\n",
    "    \n",
    "    elif fpath.name.endswith(\"_star.fits\"):\n",
    "        # mask bad pixels\n",
    "        mask = (ccd.data < max(med - 6 * std, 0))\n",
    "        bad = badpix[badpix['file'] == fpath.name]\n",
    "        if len(bad) != 0:\n",
    "            for row in bad:\n",
    "                sect = f\"[{row['xmin']}:{row['xmax']},{row['ymin']}:{row['ymax']}]\"\n",
    "                pysect = fu.fitsxy2py(sect)\n",
    "                mask[pysect] = True\n",
    "        \n",
    "        # Mask near target\n",
    "        hsize = cutsize_crrej // 2\n",
    "        hboxs = maskbox_size // 2\n",
    "        mask[hsize - hboxs:hsize + hboxs, hsize - hboxs:hsize + hboxs] = True \n",
    "        np.save(fpath.parent / (fpath.name[:-4] + 'mask'), mask)\n",
    "\n",
    "        errmap = fu.make_errmap(ccd, gain_epadu=gain_epadu, \n",
    "                                rdnoise_electron=rdnoise_e)\n",
    "        \n",
    "        # Query for PAN-STARRS        \n",
    "        coord = fu.center_coord(ccd.header)\n",
    "        ps = panstarrs.panstarrs_query(*coord, rad_deg=0.06, mindet=5)\n",
    "        ps = ps[(ps[\"ng\"] > 5) & (ps[\"gFlags\"] > 0)\n",
    "                & (ps[\"nr\"] > 5) & (ps[\"rFlags\"] > 0)]\n",
    "        \n",
    "        # Find only those within the image with bezel\n",
    "        qt = qu.xyinFOV(ccd.header, ps, \"raMean\", \"decMean\", bezel=bezel_size)\n",
    "\n",
    "        # Do DAOGROUP: Delete stars close to each other\n",
    "        qt[\"x\"].name = \"x_0\"\n",
    "        qt[\"y\"].name = \"y_0\"\n",
    "        qt = DAOGroup(crit_separation=crit_sep)(qt).group_by(\"group_id\")\n",
    "        gid, gnum = np.unique(qt[\"group_id\"], return_counts=True)\n",
    "        gmask = gid[gnum != 1]  # group id with > 1 stars\n",
    "        remove_rows = []\n",
    "        for i, gid in enumerate(qt[\"group_id\"]):\n",
    "            if gid in gmask:\n",
    "                remove_rows.append(i)\n",
    "        qt.remove_rows(remove_rows)\n",
    "        qt.remove_column(\"group_id\")\n",
    "        \n",
    "        # Remove galaxy candidates\n",
    "        maybe_galaxy = (ps[\"iMeanPSFMag\"] - ps[\"iMeanKronMag\"] > 0.05)\n",
    "        ps = ps[~maybe_galaxy]        \n",
    "        \n",
    "        # Calculate V mag by transformation\n",
    "        V, dV = qu.sdss2BV(g=qt[\"gMeanApMag\"], r=qt[\"rMeanApMag\"],\n",
    "                           gerr=qt[\"gMeanApMagErr\"], rerr=qt[\"rMeanApMagErr\"])\n",
    "        qt[\"V\"] = V\n",
    "        qt[\"dV\"] = dV\n",
    "        qt = qt[(qt[\"V\"] < catalog_Vmax) & (qt[\"V\"] > catalog_Vmin)]\n",
    "        \n",
    "        # Centroiding and reject if close to masked pixels\n",
    "        qt[\"x_c\"] = 0.0\n",
    "        qt[\"y_c\"] = 0.0\n",
    "        qt[\"shift\"] = 0.0\n",
    "        for i, row in enumerate(qt):\n",
    "            # test whether close to masked pixel\n",
    "            x_0, y_0 = [row[\"x_0\"], row[\"y_0\"]]\n",
    "            ap_i = Cap([x_0, y_0], r=r_out)   # if too many rejected, decrese r.\n",
    "            ap_val = ap_i.to_mask()[0].multiply(mask.astype(int))\n",
    "            n_mask = np.count_nonzero(ap_val)\n",
    "            if n_mask != 0:\n",
    "                x, y = np.nan, np.nan\n",
    "            else:\n",
    "                x, y = photometry.find_centroid_com(ccd, [x_0, y_0], csigma=1)\n",
    "            qt[\"x_c\"][i] = x\n",
    "            qt[\"y_c\"][i] = y\n",
    "            qt[\"shift\"][i] = np.sqrt((x - x_0)**2 + (y - y_0)**2)\n",
    "        qt = qt[(~np.isnan(qt[\"x_c\"])) & (~np.isnan(qt[\"y_c\"]))]\n",
    "\n",
    "        # Do apphot to survived stars.\n",
    "        pos = (qt[\"x_c\"], qt[\"y_c\"])\n",
    "        ap = Cap(positions=pos, r=r_ap)\n",
    "        an = Can(positions=pos, r_in=r_in, r_out=r_out)\n",
    "        phot = photometry.apphot_annulus(ccd, aperture=ap, annulus=an,\n",
    "                                         mask=mask, t_exposure=t_exp, error=errmap)\n",
    "        phot[\"file\"]=fpath.name\n",
    "        phot = hstack([phot, Table(qt.as_array())])\n",
    "        star_phots.append(phot)\n",
    "\n",
    "targ_phots_tab = vstack(targ_phots)\n",
    "star_phots_tab = vstack(star_phots)\n",
    "targ_phots_tab.write(reduc_dir / \"phot_targ.csv\")\n",
    "star_phots_tab.write(reduc_dir / \"phot_star.csv\")\n",
    "```\n",
    "-----\n",
    "\n",
    "For each of the same-night, same-observatory results, I plot the sidereal stacked image, target-centered stacked image, and linearity plot:\n",
    "\n",
    "-----\n",
    "```python\n",
    "targ_phots_tab = Table.read(reduc_dir / \"phot_targ.csv\")\n",
    "star_phots_tab = Table.read(reduc_dir / \"phot_star.csv\")\n",
    "\n",
    "def colorbaring(fig, ax, im):\n",
    "    cb = fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "    cb.ax.set_xticklabels(cb.get_ticks().astype(int), rotation=45)\n",
    "\n",
    "def reduced_mag_time(m_std, row):\n",
    "    r = row[\"r\"][0]\n",
    "    d = row[\"delta\"][0]\n",
    "    t = Time(row['datetime_jd'][0], format='jd') - row['lighttime'][0] * u.s\n",
    "    return m_std - 5.0 * np.log10(r * d), t.jd\n",
    "\n",
    "def linf(x, a=1, b=0):\n",
    "    return a * x + b\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "star_grouped = star_phots_tab.group_by('file')\n",
    "targ_stdtab = []\n",
    "for group in star_grouped.groups:\n",
    "    fname_star = group['file'][0]\n",
    "    fname_targ = fname_star[:-9] + 'targ.fits'\n",
    "    fname_png = fname_star[:-9] + '.png'\n",
    "    \n",
    "    targ_tab = targ_phots_tab[targ_phots_tab['file']==fname_targ]\n",
    "    \n",
    "    mask_star = np.load(reduc_dir / (fname_star[:-4] + 'mask.npy'))\n",
    "    mask_targ = np.load(reduc_dir / (fname_targ[:-4] + 'mask.npy'))\n",
    "    ccd_star = fu.load_ccd(reduc_dir / fname_star)\n",
    "    ccd_targ = fu.load_ccd(reduc_dir / fname_targ)\n",
    "    ccd_star.data[mask_star] = np.nan\n",
    "    ccd_targ.data[mask_targ] = np.nan\n",
    "    \n",
    "    xy_star = [group[\"xcenter\"], group[\"ycenter\"]]\n",
    "    xy_targ = [targ_tab[\"xcenter\"], targ_tab[\"ycenter\"]]\n",
    "    \n",
    "    plt.close('all')\n",
    "    fig, axs = plt.subplots(2,2, figsize=(12, 12))\n",
    "    \n",
    "    ax_star = axs[0, 0]\n",
    "    ax_targ = axs[0, 1]\n",
    "    ax_fit = axs[1, 0]\n",
    "    \n",
    "    # The \"star\" image\n",
    "    im_star = zimshow(ax_star, ccd_star.data)\n",
    "    ap_star = Cap(positions=xy_star, r=r_ap)\n",
    "    an_star = Can(positions=xy_star, r_in=r_in, r_out=r_out)\n",
    "    ap_star.plot(ax=ax_star, color='k', alpha=0.5)\n",
    "    an_star.plot(ax=ax_star, color='r', alpha=0.5)\n",
    "        \n",
    "    # The \"target\" image\n",
    "    im_targ = zimshow(ax_targ, ccd_targ.data)\n",
    "    ap_targ = Cap(positions=xy_targ, r=r_ap)\n",
    "    an_targ = Can(positions=xy_targ, r_in=r_in, r_out=r_out)\n",
    "    ap_targ.plot(ax=ax_targ, color='k')\n",
    "    an_targ.plot(ax=ax_targ, color='r')\n",
    "    \n",
    "    colorbaring(fig, ax_star, im_star)\n",
    "    colorbaring(fig, ax_targ, im_targ)\n",
    "\n",
    "    # The linearity fit    \n",
    "    xx = np.linspace(catalog_Vmin-1, catalog_Vmax+4, 2)\n",
    "    yerr = np.sqrt(group[\"merr\"]**2 + group[\"dV\"]**2)  # rough estimate\n",
    "    popt, pcov = curve_fit(linf, group[\"V\"], group[\"mag\"], sigma=yerr,\n",
    "                           absolute_sigma=True)\n",
    "    a0, b0 = popt\n",
    "    da, db = np.sqrt(np.diag(pcov))\n",
    "    m, dm = targ_tab[\"mag\"][0], targ_tab[\"merr\"][0]\n",
    "    \n",
    "    ax_fit.errorbar(group[\"V\"], group[\"mag\"], group[\"merr\"], capsize=3, ls='', \n",
    "                       marker='x', label=None)\n",
    "    ax_fit.plot(xx, linf(xx, a0, b0), 'k:',\n",
    "                label=(r\"slope$= {:.3f} \\pm {:.3f}$, \"\n",
    "                       + r\"$V_{{zp}} = {:.3f} \\pm {:.3f}$\").format(a0, da, b0, db))\n",
    "    \n",
    "    m_std = (m - b0) / a0\n",
    "    dm_std = np.sqrt( (dm / a0)**2 + (db / a0)**2 + ((m - b0)/a0**2 * da)**2)\n",
    "    H, t_target = reduced_mag_time(m_std, targ_tab)\n",
    "    lab_targ = (r\"$V(r_h, \\Delta, \\alpha) = {:.3f} \\pm {:.3f}$\"\n",
    "                + \"\\n\" \n",
    "                + r\"$V(1, 1, {:.2f}^{{\\circ}})= {:.3f} \\pm {:.3f}$\")\n",
    "    \n",
    "    ax_fit.errorbar(m_std, m, xerr=dm_std, marker='*', color='r', ms=15, \n",
    "                    mfc='none',\n",
    "                    label=lab_targ.format(m_std, dm_std, targ_tab[\"alpha\"][0], \n",
    "                                          H, dm_std))\n",
    "    ax_fit.set_xlim(catalog_Vmin, catalog_Vmax+1)\n",
    "    ax_fit.set_ylim(catalog_Vmin+b0, catalog_Vmax+2+b0)\n",
    "    ax_fit.grid()\n",
    "    ax_fit.set_xlabel((r\"$V$ [mag] (From PS1, \"\n",
    "                       + r\"Lupton 2005 gr $\\rightarrow$ V transformation)\"))\n",
    "    ax_fit.set_ylabel(r\"$V_\\mathrm{{inst}}$ [mag]\")\n",
    "    ax_fit.legend(loc=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(reduc_dir / fname_png)\n",
    "    plt.close('all')\n",
    "\n",
    "    targ_tab[\"m_std\"] = m_std\n",
    "    targ_tab[\"m_red\"], targ_tab[\"merr_red\"] = H, dm_std\n",
    "    targ_tab[\"t_target\"] = t_target\n",
    "    targ_stdtab.append(targ_tab)\n",
    "    \n",
    "targ_stdtab = vstack(targ_stdtab)\n",
    "targ_stdtab.write(reduc_dir / \"phot_targ.csv\")\n",
    "```\n",
    "-----\n",
    "\n",
    "An example of the resulting plot is shown below (Siding Spring Observatory, on 2018-04-09):\n",
    "\n",
    "![](figs/20180409SSO_.png)\n",
    "\n",
    "* Black circles: aperture used for aperture photometry\n",
    "* Red annuli: annular regions to estimate sky\n",
    "* White regions (NaN pixels): where saturation/blooming occured, or the stellar pixels near the target.\n",
    "\n",
    "As a result, I obtained the following ``phot_targ.csv`` file (you may just copy-and-paste it and save as a csv file):\n",
    "\n",
    "```\n",
    "id,xcenter,ycenter,aperture_sum,aperture_sum_err,msky,nrej,nsky,ssky,source_sum,source_sum_err,mag,merr,file,datetime_jd,RA_deg,DEC_deg,RA_rate,DEC_rate,RA_3sigma,DEC_3sigma,V_JPL,r,r_rate,delta,delta_rate,lighttime,alpha,ObsEclLon,ObsEclLat,m_std,m_red,merr_red,t_target\n",
    "1,99.99826896238706,100.50631546021809,81228.67873959502,255.91276044857713,692.2071042720206,11,998,16.290871775954447,2941.8996120238444,262.47434405697203,-4.226191496508501,0.09686866846103874,20180407CTIO_targ.fits,2458215.633683866,205.85845,-10.0691,-0.009155277777777778,0.0034482916666666668,0.009,0.002,20.76,3.806683070634,4.7604286,2.81843518127849,-0.9680001,1406.4126600000002,2.7863,207.8744685,0.5951508,21.503228340750695,16.35045448078801,0.1719984166452296,2458215.6174059417\n",
    "1,100.40303782933367,99.80724669423635,102775.99914360391,288.9277031429431,857.3189814781076,3,1005,20.021498903788935,5815.506639794461,297.6257997674568,-4.966090763826891,0.05556577032625354,20180407SAAO_targ.fits,2458216.405011574,205.68906,-10.00459,-0.009193888888888889,0.003468825,0.009,0.002,20.75,3.808800126846,4.744184,2.81819363840852,-0.4916773,1406.29212,2.5429,207.6956768,0.5956415,20.915617677742794,15.761822611981717,0.08933435443783663,2458216.3887350447\n",
    "1,100.2878085282523,100.99861602015855,170802.85745460697,367.2786117326402,1451.058447817702,7,995,21.83494174715075,6692.013309240952,375.5296577910269,-5.118513864107845,0.06092727652844363,20180407SSO_targ.fits,2458216.028442847,205.77185,-10.03613,-0.009174944444444446,0.0034580277777777777,0.009,0.002,20.75,3.807767466496,4.7521132,2.81828827593016,-0.735526,1406.33934,2.6618,207.7830704,0.5954059,21.231171247936654,16.077892083318353,0.10455153304691477,2458216.0121657713\n",
    "1,100.20665605624994,101.40262104855,83171.50572924544,266.29363539544,673.9933725940132,41,965,17.77032176326622,6944.651124501281,274.0401420729421,-5.158747956924872,0.04284380863365858,20180409CTIO_targ.fits,2458217.632635035,205.41864,-9.90146,-0.009234777777777778,0.003487088888888889,0.009,0.002,20.72,3.812154651092,4.7183545,2.81820122948009,0.1406328,1406.2959,2.155,207.4101172,0.5963184,20.793535975029588,15.637823421174996,0.09223824973234893,2458217.6163584623\n",
    "1,99.79915709379121,100.59602603304214,75082.18214603269,261.8661900776252,620.7988004414439,123,883,16.443825304827968,4871.491916361629,269.24128037128196,-4.773776839612017,0.06000728543399984,20180409SSO_targ.fits,2458218.026400463,205.33161,-9.86823,-0.009248111111111111,0.0034945777777777775,0.009,0.002,20.71,3.813226749507,4.7100761,2.81830448170511,0.3727141,1406.34744,2.0303,207.3181792,0.5965186,20.633049389724587,15.476646678876229,0.09914327668597976,2458218.010123294\n",
    "1,99.99989983035023,100.66391552974753,99003.26277937792,288.17647209607657,800.97166015625,4,1000,20.546478150697816,8415.502181280099,297.3978851933971,-5.367321966279652,0.03836914829530191,20180411SAAO_targ.fits,2458220.405226215,204.80418,-9.66645,-0.00930275,0.0035281555555555554,0.009,0.002,20.65,3.819663512052,4.6601303,2.81998375479874,1.7498716,1407.1854,1.277,206.7606667,0.5974695,20.283336610683,15.121978048204145,0.09840092613400866,2458220.3889393467\n",
    "1,100.14854072428979,100.56932181524242,59509.78974848555,219.12869819588786,479.75074752898627,2,1006,13.279781482249115,5251.258484799655,224.18666346830057,-4.855280364701986,0.04635223686970097,20180411SSO_targ.fits,2458220.031770833,204.88716,-9.69826,-0.009297583333333333,0.0035220416666666664,0.009,0.002,20.66,3.818657536576,4.6679639,2.81960014156878,1.5108372,1406.9939399999998,1.3952,206.8484332,0.5973361,20.490131739336242,15.329640561412049,0.08618237507460365,2458220.015486181\n",
    "1,100.1852531138403,100.394401420998,50513.377618852035,199.9605999334698,410.57962321942273,30,977,15.37205900261952,4077.916210139105,207.55219473747636,-4.580717619009562,0.05526031448198902,20180413CTIO_targ.fits,2458221.631400463,204.5318,-9.56199,-0.009310249999999999,0.0035330500000000003,0.009,0.002,20.62,3.822954572921,4.6344297,2.82156061051997,2.3873702,1407.97224,0.8906,206.4725259,0.5977997,20.48608785709762,15.321645250462767,0.12419296907641106,2458221.615104488\n",
    "1,99.99276753806915,100.00501913411503,131999.45199560787,327.89806515177463,1088.915180536343,2,994,21.35254671353093,8846.046459614241,336.7256497898473,-5.421494913948251,0.041328658030074,20180413SAAO_targ.fits,2458222.405691771,204.3596,-9.49585,-0.009314555555555557,0.003541575,0.009,0.002,20.59,3.825023401629,4.6182159,2.82280436711817,2.8821393,1408.5928800000002,0.649,206.290274,0.5979584,20.770045464851552,15.603471078952042,0.0909828006208629,2458222.3893886125\n",
    "```\n",
    "\n",
    "To generate a TeX-like table, I used the following code:\n",
    "```python\n",
    "from astropy.io.ascii.latex import latexdicts\n",
    "tab = Table.read(reduc_dir / \"phot_targ.csv\")\n",
    "\n",
    "tab1 = dict(date=[], time=[], observatory=[], N=[])\n",
    "for fpath in tab[\"file\"]:\n",
    "    hdr = fits.getheader(reduc_dir / fpath)\n",
    "    N = hdr[\"NCOMBINE\"]\n",
    "    t = Time(hdr[\"MEANTIME\"], precision=0)\n",
    "    obs = hdr[\"OBSERVAT\"]\n",
    "    date = t.datetime.strftime(\"%Y-%m-%d\")\n",
    "    time = t.datetime.strftime(\"%H:%M:%S\")\n",
    "    tab1[\"N\"].append(N)\n",
    "    tab1[\"date\"].append(date)\n",
    "    tab1[\"time\"].append(time)\n",
    "    tab1[\"observatory\"].append(obs)\n",
    "tab1 = Table(tab1)\n",
    "tab2 = tab[[\"r\", \"delta\", \"alpha\", \"m_std\", \"merr_red\", \"m_red\"]]\n",
    "tab2 = hstack([tab1, tab2])\n",
    "\n",
    "tab2[\"alpha\"].unit = u.deg\n",
    "for c in [\"r\", \"delta\"]:\n",
    "    tab2[c].format = '.4f'\n",
    "    tab2[c].unit = u.au\n",
    "for c in [\"m_std\", \"merr_red\", \"m_red\"]:\n",
    "    tab2[c].format = '.3f'\n",
    "    tab2[c].unit = u.mag\n",
    "\n",
    "tab2.write(\"test.tex\", format='ascii.latex', latexdict=latexdicts[\"AA\"])\n",
    "```\n",
    "\n",
    "The result:\n",
    "```\n",
    "\\begin{table}\n",
    "\\begin{tabular}{cccccccccc}\n",
    "\\hline \\hline\n",
    "date & time & observatory & N & r & delta & alpha & m_std & merr_red & m_red \\\\\n",
    " &  &  &  & $\\mathrm{AU}$ & $\\mathrm{AU}$ & $\\mathrm{{}^{\\circ}}$ & $\\mathrm{mag}$ & $\\mathrm{mag}$ & $\\mathrm{mag}$ \\\\\n",
    "\\hline\n",
    "2018-04-07 & 03:12:30 & CTIO & 7 & 3.8067 & 2.8184 & 2.7863 & 21.503 & 0.172 & 16.350 \\\\\n",
    "2018-04-07 & 21:43:13 & SAAO & 10 & 3.8088 & 2.8182 & 2.5429 & 20.916 & 0.089 & 15.762 \\\\\n",
    "2018-04-07 & 12:40:57 & SSO & 13 & 3.8078 & 2.8183 & 2.6618 & 21.231 & 0.105 & 16.078 \\\\\n",
    "2018-04-09 & 03:10:59 & CTIO & 9 & 3.8122 & 2.8182 & 2.155 & 20.794 & 0.092 & 15.638 \\\\\n",
    "2018-04-09 & 12:38:01 & SSO & 10 & 3.8132 & 2.8183 & 2.0303 & 20.633 & 0.099 & 15.477 \\\\\n",
    "2018-04-11 & 21:43:31 & SAAO & 11 & 3.8197 & 2.8200 & 1.277 & 20.283 & 0.098 & 15.122 \\\\\n",
    "2018-04-11 & 12:45:45 & SSO & 5 & 3.8187 & 2.8196 & 1.3952 & 20.490 & 0.086 & 15.330 \\\\\n",
    "2018-04-13 & 03:09:13 & CTIO & 4 & 3.8230 & 2.8216 & 0.8906 & 20.486 & 0.124 & 15.322 \\\\\n",
    "2018-04-13 & 21:44:11 & SAAO & 13 & 3.8250 & 2.8228 & 0.649 & 20.770 & 0.091 & 15.603 \\\\\n",
    "\\hline\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDSS to V Conversion\n",
    "The PS1 catalog is in SDSS filter system, so we had to convert the magnitudes into Johnson-Cousins V filter magnitude. According to SDSS, there are two possible ways for the conversion: Jester et al. (2005) & Lupton (2005) ([link](http://www.sdss3.org/dr8/algorithms/sdssUBVRITransform.php)):\n",
    "\n",
    "* Jester: $ V = g - 0.59 (g - r) - 0.01 $ (RMS 0.01)\n",
    "* Lupton: $ V = g - 0.5784 * (g - t) - 0.0038 $ (RMS 0.0054)\n",
    "\n",
    "In the code below, I queried PS1 near one of our image (with at least 5 observations in both g and r with non-zero quality flag in g and r, and removed possible galactic sources by method described in [this link](https://outerspace.stsci.edu/display/PANSTARRS/How+to+separate+stars+and+galaxies)). \n",
    "\n",
    "```python\n",
    "ccd_1_cr = fits.open('../crrej_1k/20180413SAAO_p4179_010461.fits')[0]\n",
    "fig, axs = plt.subplots(1,3)\n",
    "coord = fu.center_coord(ccd_1_cr.header, skycoord=True)\n",
    "wcs = WCS(ccd_1_cr.header)\n",
    "zimshow(axs[0], ccd_1_cr.data)\n",
    "\n",
    "test_query = panstarrs.panstarrs_query(coord.ra.value, coord.dec.value, 0.06, mindet=5)\n",
    "test_query = test_query[(test_query[\"ng\"] > 5) \n",
    "                        & (test_query[\"nr\"] > 5)\n",
    "                        & (test_query[\"gFlags\"] > 0)\n",
    "                        & (test_query[\"rFlags\"] > 0)]\n",
    "maybe_galaxy = test_query[\"iMeanPSFMag\"] - test_query[\"iMeanKronMag\"] > 0.05\n",
    "# https://outerspace.stsci.edu/display/PANSTARRS/How+to+separate+stars+and+galaxies\n",
    "\n",
    "test_query = test_query[~maybe_galaxy]\n",
    "axs[1].plot(test_query[\"gMeanPSFMag\"], \n",
    "            test_query[\"gMeanPSFMag\"] - test_query[\"gMeanApMag\"], \n",
    "            'ro', mfc='none', label=\"PSF - Ap\")\n",
    "axs[1].plot(test_query[\"gMeanPSFMag\"], \n",
    "            test_query[\"gMeanPSFMag\"] - test_query[\"gMeanKronMag\"], \n",
    "            'bo', mfc='none', label=\"PSF - Kron\")\n",
    "axs[1].plot(test_query[\"gMeanPSFMag\"], \n",
    "            test_query[\"gMeanApMag\"] - test_query[\"gMeanKronMag\"], \n",
    "            'go', mfc='none', label=\"Ap - Kron\")\n",
    "axs[1].legend()\n",
    "axs[1].set_xlabel(\"Mean PSF magnitude\")\n",
    "axs[1].set_title(\"g-band analysis\")\n",
    "\n",
    "test_query[\"Vmag1\"] = (test_query[\"gMeanPSFMag\"] \n",
    "                      - 0.59 * (test_query[\"gMeanPSFMag\"] - test_query[\"rMeanPSFMag\"]) \n",
    "                      - 0.01)\n",
    "test_query[\"Vmag2\"] = (test_query[\"gMeanPSFMag\"] \n",
    "                      - 0.5784 * (test_query[\"gMeanPSFMag\"] - test_query[\"rMeanPSFMag\"]) \n",
    "                      - 0.0038)\n",
    "axs[2].plot(test_query[\"Vmag2\"], test_query[\"Vmag1\"] - test_query[\"Vmag2\"], 'rx')\n",
    "axs[2].set_xlabel(\"Lupton V mag\")\n",
    "axs[2].set_ylabel(\"Jester - Lupton V mag\")\n",
    "# Use of Vmag1 (2) will systematically decrease (increase) the magnitude of our \n",
    "# target by 0.13 mag.\n",
    "# Jester et al. (2005) & Lupton (2005)\n",
    "# http://www.sdss3.org/dr8/algorithms/sdssUBVRITransform.php\n",
    "\n",
    "#for row in test_query:\n",
    "#    variable = str(bin(row[\"objInfoFlag\"]))[-9]\n",
    "#    print(variable)\n",
    "    \n",
    "# Test if within [+30:-30, +30:-30] region\n",
    "# Test if within V_JPL +- 5 mag\n",
    "\n",
    "query_xy = wcs.wcs_world2pix(test_query[\"raMean\"], test_query[\"decMean\"], 0)\n",
    "axs[0].plot(*query_xy, 'ro', mfc='none')\n",
    "for i in range(len(query_xy[0])):\n",
    "    V = test_query[\"Vmag2\"][i]\n",
    "    if V > 17 and V < 20:\n",
    "        axs[0].text(query_xy[0][i], query_xy[1][i], \"{:.1f}\".format(V), \n",
    "           color='k', fontweight=\"bold\")\n",
    "    else:\n",
    "        axs[0].text(query_xy[0][i], query_xy[1][i], \"{:.1f}\".format(V), \n",
    "           color='orange', fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "```\n",
    "\n",
    "The resulting image is like this:\n",
    "![](figs/SDSS2V_Conversion.png)\n",
    "\n",
    "* *left*: The black numbers are the stars with 17 < V < 20 mag. In our photometry, we used stars that have 15 < V < 20 mag.\n",
    "* *middle*: Comparison of gmag values from PS1 (Ap = aperture, PSF = point-spread function, Kron = Kron radius photometry).\n",
    "* *right*: Comparison of two possible SDSS-to-V conversions.\n",
    "\n",
    "Note the systematic offsets between \n",
    "1. (PSF and Ap mag) and Kron mag \n",
    "  * The dispersion of data points gets larger when PSF mag $ \\gtrsim 20 $ mag. We used PSF mag throughout our work.\n",
    "2. Jester and Lupton conversions. \n",
    "  * The conversion used PSF mag. You can see Jester and Lupton conversion has systematic offset of ~ 0.015 mag (~ 1.5 % of the flux), regardless of the type of the point sources.\n",
    "\n",
    "In the publication, we used Lupton's conversion formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
